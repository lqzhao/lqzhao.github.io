<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Lei Chen</title>
 
    <meta name="author" content="Chen Lei">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <style>
  .justify-text { text-align: justify; width: 400px; /* 或者其他宽度 */}
</style>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle;text-align: justify">
                <p class="name" style="text-align: center;">
                  Lei Chen（陈 磊）
                </p>
                <p>
                  I'm currently a Assistant Researchor of <a href="https://www.au.tsinghua.edu.cn/en/index.htm">Department of Automation</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, China. Before that, I was an Associate Professor  with the <a href="http://scce.ustb.edu.cn/">School of Computer and Communication Engineering</a>, <a href="https://en.ustb.edu.cn/">University of Science and Technology Beijing</a>, China (Nov. 2022 to Jan. 2024). And I was a postdoctoral researcher of Department of Automation, Tsinghua University, China (Jun. 2020 to Oct. 2022). My current research interests lie in computer vision and pattern recognition.
                <br> 
                <br> 
                  I received the B.S. degree in the Qiushi Honers college, and the Ph.D degree with the school of electrical and information engineering, Tianjin University, China, in 2013 and 2020. I finished my PhD research at Tsinghua University advised by <a href="https://www.au.tsinghua.edu.cn/info/1152/3127.htm">Prof. Jie Zhou</a>, <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a> and Prof. Zhanjie Song.
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/LeiChen.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 10%;" alt="profile photo" src="images/LeiChen.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;text-align: justify">
                <h2>Recent Selected Publications</h2>
                <p>
                  (*Equal Contribution, #Corresponding Author)
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>





    <tr onmouseout="AASE_stop()" onmouseover="AASE_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='AASE'><video  width=100% muted autoplay loop>
          <source src="images/AASE.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/AASE.png' width=100%>
        </div>
        <script type="text/javascript">
          function AASE_start() {
            document.getElementById('AASE').style.opacity = "1";
          }

          function AASE_stop() {
            document.getElementById('AASE').style.opacity = "0";
          }
          AASE_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Ambiguousness-Aware State Evolution for Action Prediction </span>  
        <br>      
        <span class="author"><strong>Lei Chen</strong>, Jiwen Lu#, Zhanjie Song, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2022. </em></span>
        <br> 
        <p>
          We propose an ambiguousness-aware state evolution (AASE) method which represents the uncertainty of the input sequence and evolves the subsequent skeletons to generate a reasonable full-length sequence for action prediction.
        </p> 
      </td>
    </tr>

    <tr onmouseout="ORCL_stop()" onmouseover="ORCL_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='ORCL'><video  width=100% muted autoplay loop>
          <source src="images/ORCL.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/ORCL.png' width=100%>
        </div>
        <script type="text/javascript">
          function ORCL_start() {
            document.getElementById('ORCL').style.opacity = "1";
          }

          function ORCL_stop() {
            document.getElementById('ORCL').style.opacity = "0";
          }
          ORCL_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Order-Constrained Representation Learning for Instructional Video Prediction </span>  
        <br>      
        <span class="author">Muheng Li*, <strong>Lei Chen*</strong>, Jiwen Lu#, Jianjiang Feng, and Jie Zhou </span>       
        <br> 
        <span class="publications"><em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2022. </em></span>
        <br> 
        <p>
          We propose a weakly-supervised approach called Order-Constrained Representation Learn-ing (OCRL) to predict future actions from instructional videos by observing incomplete steps of actions.
        </p> 
      </td>
    </tr>

    <tr onmouseout="RSPG_stop()" onmouseover="RSPG_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='RSPG'><video  width=100% muted autoplay loop>
          <source src="images/RSPG.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/RSPG.png' width=100%>
        </div>
        <script type="text/javascript">
          function RSPG_start() {
            document.getElementById('RSPG').style.opacity = "1";
          }

          function RSPG_stop() {
            document.getElementById('RSPG').style.opacity = "0";
          }
          RSPG_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Recurrent Semantic Preserving Generation for Action Prediction </span>  
        <br>      
        <span class="author"><strong>Lei Chen</strong>, Jiwen Lu#, Zhanjie Song, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2021. </em></span>
        <br> 
        <p>
          We propose a recurrent semantic preserving generation (RSPG) method for action prediction. Our method learns to capture the tendency of observed sequences and complement the subsequent action with adversarial learning under some constrains, which preserves the consistency between the generation sequence and the observed sequence.
        </p> 
      </td>
    </tr>  

    <tr onmouseout="PORD_stop()" onmouseover="PORD_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='PORD'><video  width=100% muted autoplay loop>
          <source src="images/PORD.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/PORD.png' width=100%>
        </div>
        <script type="text/javascript">
          function PORD_start() {
            document.getElementById('PORD').style.opacity = "1";
          }

          function PORD_stop() {
            document.getElementById('PORD').style.opacity = "0";
          }
          PORD_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Learning Principal Orientations and Residual Descriptor for Action Recognition </span>  
        <br>      
        <span class="author"><strong>Lei Chen</strong>, Zhanjie Song#, Jiwen Lu, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>Pattern Recognition (<strong>PR</strong>), 2019. </em></span>
        <br> 
        <p>
          We propose an unsupervised representation method to learn principal orientations and residual descriptor (PORD) for action recognition. Our PORD aims to learn the statistic principal orientations and to represent the local features of action videos with residual values.
        </p> 
      </td>
    </tr>  

    <tr onmouseout="HSGE_stop()" onmouseover="HSGE_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='HSGE'><video  width=100% muted autoplay loop>
          <source src="images/HSGE.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/HSGE.png' width=100%>
        </div>
        <script type="text/javascript">
          function HSGE_start() {
            document.getElementById('HSGE').style.opacity = "1";
          }

          function HSGE_stop() {
            document.getElementById('HSGE').style.opacity = "0";
          }
          HSGE_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Hypersphere Guided Embedding for Masked Face Recognition </span>  
        <br>      
        <span class="author">Kai Li, Xiaobin Zhu, Song-Lu Chen, Feng Chen, Xu-Cheng Yin, <strong>Lei Chen#</strong> </span>       
        <br> 
        <span class="publications"><em>Pattern Recognition Letters (<strong>PRL</strong>), 2023. </em></span>
        <br> 
        <p>
           We propose a framework to enable existing methods to accommodate multiple data distributions by orthogonal subspaces. We introduce constraints on multiple hypersphere manifolds via MultiCenter Loss and employ a Spatial Split Strategy to ensure the orthogonality of base vectors associated with different hypersphere manifolds, corresponding to distinct distribution.
        </p> 
      </td>
    </tr>     

    <tr onmouseout="PA_DRL_stop()" onmouseover="PA_DRL_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='PA_DRL'><video  width=100% muted autoplay loop>
          <source src="images/PA_DRL.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/PA_DRL.png' width=100%>
        </div>
        <script type="text/javascript">
          function PA_DRL_start() {
            document.getElementById('PA_DRL').style.opacity = "1";
          }

          function PA_DRL_stop() {
            document.getElementById('PA_DRL').style.opacity = "0";
          }
          PA_DRL_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Part-Activated Deep Reinforcement Learning for Action Prediction </span>  
        <br>      
        <span class="author"><strong>Lei Chen</strong>, Jiwen Lu#, Zhanjie Song, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>European Conference on Computer Vision (<strong>ECCV</strong>), 2018. </em></span>
        <br> 
        <p>
           We propose a part-activated deep reinforcement learning (PA-DRL) method for action prediction. We design the PA-DRL to exploit the structure of the human body by extracting skeleton proposals under a deep reinforcement learning framework.
        </p> 
      </td>
    </tr>         

    <tr onmouseout="UARL_stop()" onmouseover="UARL_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='UARL'><video  width=100% muted autoplay loop>
          <source src="images/UARL.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/UARL.png' width=100%>
        </div>
        <script type="text/javascript">
          function UARL_start() {
            document.getElementById('UARL').style.opacity = "1";
          }

          function UARL_stop() {
            document.getElementById('UARL').style.opacity = "0";
          }
          UARL_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Uncertainty-Aware Representation Learning for Action Segmentation </span>  
        <br>      
        <span class="author"><strong>Lei Chen</strong>, Muheng Li, Yueqi Duan, Jie Zhou#, Jiwen Lu </span>       
        <br> 
        <span class="publications"><em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2022. </em></span>
        <br> 
        <p>
           We propose an uncertainty-aware representation Learning (UARL) method for action segmentation. we design the UARL to exploit the transitional expression between two action periods by uncertainty learning.
        </p> 
      </td>
    </tr>     

    <tr onmouseout="SPPP_stop()" onmouseover="SPPP_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='SPPP'><video  width=100% muted autoplay loop>
          <source src="images/SPPP.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/SPPP.png' width=100%>
        </div>
        <script type="text/javascript">
          function SPPP_start() {
            document.getElementById('SPPP').style.opacity = "1";
          }

          function SPPP_stop() {
            document.getElementById('SPPP').style.opacity = "0";
          }
          SPPP_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Skip-Plan: Procedure Planning in Instructional Videos via Condensed Action Space Learning </span>  
        <br>      
        <span class="author">Zhiheng Li, Wenjia Geng, Muheng Li, <strong>Lei Chen</strong>, Yansong Tang#, Jiwen Lu, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023. </em></span>
        <br> 
        <p>
           We propose Skip-Plan, a condensed action space learning method for procedure planning in instructional videos. we abstract the procedure planning problem as a mathematical chain model.
        </p> 
      </td>
    </tr>    

    <tr onmouseout="Br_Prompt_stop()" onmouseover="Br_Prompt_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='Br_Prompt'><video  width=100% muted autoplay loop>
          <source src="images/Br_Prompt.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/Br_Prompt.png' width=100%>
        </div>
        <script type="text/javascript">
          function Br_Prompt_start() {
            document.getElementById('Br_Prompt').style.opacity = "1";
          }

          function Br_Prompt_stop() {
            document.getElementById('Br_Prompt').style.opacity = "0";
          }
          Br_Prompt_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos </span>  
        <br>      
        <span class="author">Muheng Li, <strong>Lei Chen</strong>, Yueqi Duan,, Zhilan Hu,, Jianjiang Feng, Jie Zhou, Jiwen Lu# </span>       
        <br> 
        <span class="publications"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022. </em></span>
        <br> 
        <p>
           We propose a prompt-based framework, Bridge-Prompt (Br-Prompt), to model the semantics across adjacent actions, so that it simultaneously exploits both out-of-context and contextual information from a series of ordinal actions in instructional videos.
        </p> 
      </td>
    </tr>   

    <tr onmouseout="DE_DSP_stop()" onmouseover="DE_DSP_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='DE_DSP'><video  width=100% muted autoplay loop>
          <source src="images/DE_DSP.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/DE_DSP.png' width=100%>
        </div>
        <script type="text/javascript">
          function DE_DSP_start() {
            document.getElementById('DE_DSP').style.opacity = "1";
          }

          function DE_DSP_stop() {
            document.getElementById('DE_DSP').style.opacity = "0";
          }
          DE_DSP_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Deep Embedding Learning with Discriminative Sampling Policy </span>  
        <br>      
        <span class="author">Yueqi Duan, <strong>Lei Chen</strong>, Jiwen Lu#, Jie Zhou </span>       
        <br> 
        <span class="publications"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019. </em></span>
        <br> 
        <p>
           We propose a deep embedding with discriminative sampling policy (DE-DSP) learning framework by simultaneously training two models: a deep sampler network that learns effective sampling strategies, and a feature embedding that maps samples to the feature space.
        </p> 
      </td>
    </tr>   

    <tr onmouseout="HEL_stop()" onmouseover="HEL_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='HEL'><video  width=100% muted autoplay loop>
          <source src="images/HEL.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/HEL.png' width=100%>
        </div>
        <script type="text/javascript">
          function HEL_start() {
            document.getElementById('HEL').style.opacity = "1";
          }

          function HEL_stop() {
            document.getElementById('HEL').style.opacity = "0";
          }
          HEL_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Sample Weighting with Hierarchical Equalization Loss for Dense Object Detection </span>  
        <br>      
        <span class="author">Jia-Wei Ma, Min Liang, <strong>Lei Chen#</strong>, Shu Tian, Song-Lu Chen, Jingyan Qin#, and Xu-Cheng Yin</span>       
        <br> 
        <span class="publications"><em>IEEE Transactions on Multimedia (<strong>TMM</strong>), 2024. </em></span>
        <br> 
        <p>
           We propose a hierarchical equalization loss (HEL) by reconsidering the underlying factors affecting sample weights.
        </p> 
      </td>
    </tr>   

    <tr onmouseout="MVTCL_stop()" onmouseover="MVTCL_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='MVTCL'><video  width=100% muted autoplay loop>
          <source src="images/MVTCL.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/MVTCL.png' width=100%>
        </div>
        <script type="text/javascript">
          function MVTCL_start() {
            document.getElementById('MVTCL').style.opacity = "1";
          }

          function MVTCL_stop() {
            document.getElementById('MVTCL').style.opacity = "0";
          }
          MVTCL_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Learning Multi-Scale Video-Text Correspondence for Weakly Supervised Temporal Article Grounding </span>  
        <br>      
        <span class="author">Wenjia Geng, Yong Liu, <strong>Lei Chen#</strong>, Sujia Wang, Jie Zhou, Yansong Tang</span>       
        <br> 
        <span class="publications"><em>AAAI Conference on Artificial Intelligence(<strong>AAAI</strong>), 2024. </em></span>
        <br> 
        <p>
           We propose a Multi-Scale Video-Text Correspondence Learning (MVTCL) framework, which enhances the grounding performance in complex scenes by modeling multi-scale semantic correspondence both within and between modalities.
        </p> 
      </td>
    </tr>   

    <tr onmouseout="LRCDD_stop()" onmouseover="LRCDD_start()">
      <td style="padding:20px;width:25%;vertical-align:top;text-align: justify">
        <div class="one">
          <div class="two" id='LRCDD'><video  width=100% muted autoplay loop>
          <source src="images/LRCDD.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/LRCDD.png' width=100%>
        </div>
        <script type="text/javascript">
          function LRCDD_start() {
            document.getElementById('LRCDD').style.opacity = "1";
          }

          function LRCDD_stop() {
            document.getElementById('LRCDD').style.opacity = "0";
          }
          LRCDD_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top;text-align: justify">
        <span class="papertitle">Transfer subspace learning via label release and contribution degree distinction </span>  
        <br>      
        <span class="author">Xiaojin Fan, Ruitao Hou, <strong>Lei Chen</strong>, Liehuang Zhu, Jingjing Hu#</span>       
        <br> 
        <span class="publications"><em>Information Sciences, 2023. </em></span>
        <br> 
        <p>
           We propose a Label Release and Contribution Degree Distinction (LRCDD)-based transfer subspace learning strategy to enhance recognition performance to solve these problems. 
        </p> 
      </td>
    </tr>   

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Academic Services</h2>
                <ul class="circle-list">
                  <li>Guest Editor: JVCI</li>
                  <li>Conference Reviewer: CVPR, ICCV, ECCV, AAAI and so on</li>
                  <li>Journal Reviewer: TIP, TMM, TCSVT and so on</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        </td>
      </tr>
    </table>
  </body>
</html>
